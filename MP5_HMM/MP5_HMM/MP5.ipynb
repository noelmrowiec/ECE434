{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECE/CS 434 | MP5: HMM\n",
    "<br />\n",
    "<nav>\n",
    "    <span class=\"alert alert-block alert-warning\">Due at 11:59PM Apr 15th 2024 on Gradescope</span>\n",
    "</nav><br> \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n",
    "In this MP, you will:\n",
    "- Explore two fundamental problems that are of interest to Hidden Markov Models (HMM):\n",
    "    - What is the probability of a specific sequence of observations occuring given an HMM?\n",
    "    - What is the optimal hidden state sequence given a sequence of observations and an HMM?\n",
    "- Implement either the forward or backward algorithm to answer the first problem.\n",
    "- Implement the Viterbi algorithm to answer the second problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## References\n",
    "Material in this MP is adapted from the iconic paper *A Tutorial on Hidden Markov Models and Selected Applications in Speech Recognition* by Lawrence R. Rabiner. You are encouraged to follow the pseudocode in this paper for your implementation.\n",
    "\n",
    "You are highly encouraged to watch [this video](https://www.youtube.com/watch?v=MPeedE6Odj0) by Prof.Patterson from Westmont College before beginning the MP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Imports & Setup\n",
    "\n",
    "### Installing requirements correctly\n",
    "\n",
    "First. we will make sure that the correct versions of required modules are installed. This ensures that your local Python environment is consistent with the one running on the Gradescope autograder. Just convert the following cell to code and run:\n",
    "\n",
    "<div class=\"alert alert-block alert-info\"><b>Note:</b> It's preferred that your local environment matches the autograder to prevent possible inconsistencies. However, if you're running into annoying Python version issues but haven't had any issues getting consistent results on the autograder, there is no need to stress over it. Just skip for now and come back when you do encounter inconsistencies:) Ditto below.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\"><b>WARNING:</b> ENSURE THE FOLLOWING CELL IS MARKDOWN OR DELETED BEFORE SUBMITTING. THE AUTOGRADER WILL FAIL OTHERWISE.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if __name__ == '__main__':\n",
    "    import sys\n",
    "    !{sys.executable} -m pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your imports\n",
    "Write your import statements below. If Gradescope reports an error and you believe it is due to an unsupported import, check with the TA to see if it could be added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import scipy\n",
    "import pandas as pd\n",
    "\n",
    "# This function is used to format test results. You don't need to touch it.\n",
    "def display_table(data):\n",
    "    from IPython.display import HTML, display\n",
    "\n",
    "    html = \"<table>\"\n",
    "    for row in data:\n",
    "        html += \"<tr>\"\n",
    "        for field in row:\n",
    "            html += \"<td><h4>{}</h4><td>\".format(field)\n",
    "        html += \"</tr>\"\n",
    "    html += \"</table>\"\n",
    "    display(HTML(html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Constructing an HMM\n",
    "Recall that an HMM consists of three parameters:\n",
    "- $A$, the state transition probability matrix of size $N\\times N$, where $N$ represents the number of hidden states(or true states).\n",
    "- $B$, the observation probability matrix of size $N\\times M$, where $M$ represents the number of observed states.\n",
    "- $\\pi$, an initial distribution vector of size $1\\times N$\n",
    "\n",
    "In this MP, we will be randomly generating these parameters. Run the cell below to see what a model looks like and how to access it. Notice you'll get slightly different numbers each time you run due to the random functions used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A - State Transition Probability Matrix\n",
      "          0         1         2         3         4\n",
      "0  0.282549  0.209212  0.372559  0.135680  0.000000\n",
      "1  0.465455  0.153957  0.068227  0.312361  0.000000\n",
      "2  0.287679  0.000000  0.589609  0.029587  0.093125\n",
      "3  0.223858  0.310132  0.114584  0.351426  0.000000\n",
      "4  0.281112  0.148761  0.000000  0.436989  0.133139\n",
      "The probability of transitioning from state 2 to state 3 is 0.029586610302449776\n",
      "\n",
      "\n",
      "B - Observation Probability Matrix\n",
      "          0         1         2\n",
      "0  0.621509  0.378491  0.000000\n",
      "1  0.000000  0.219171  0.780829\n",
      "2  0.000000  0.380041  0.619959\n",
      "3  0.000000  0.303258  0.696742\n",
      "4  0.156549  0.000000  0.843451\n",
      "The probability of being in hidden state 1 while observing observable state 2 is 0.7808288224174776\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    def generate_matrix(R, C, mode):\n",
    "        model = np.zeros((R, C))\n",
    "        for i in range(R):\n",
    "            row = np.zeros(C)\n",
    "            if(mode == 0):\n",
    "                while(row.sum() != 1):\n",
    "                    row = np.random.normal(0, 2, C)\n",
    "                    row = row - row.min()\n",
    "                    row = row / row.sum()\n",
    "            elif(mode == 1):\n",
    "                while(row.sum() != 1):\n",
    "                    row = np.random.dirichlet(np.ones(C),size=1)\n",
    "                    row = row / row.sum()\n",
    "            elif(mode == 2):\n",
    "                while(row.sum() != 1):\n",
    "                    row = np.random.gamma(5, 5, C)\n",
    "                    row = row / row.sum()\n",
    "            model[i] = row\n",
    "        return model\n",
    "    \n",
    "    pi = np.ones(5)\n",
    "    pi = pi / pi.sum()\n",
    "    example_model = {'A': generate_matrix(5, 5, 0), 'B': generate_matrix(5, 3, 0), 'pi': pi}\n",
    "    print('A - State Transition Probability Matrix')\n",
    "    print(pd.DataFrame(example_model['A']))\n",
    "    print('The probability of transitioning from state 2 to state 3 is ' + str(example_model['A'][2][3]))\n",
    "    print('\\n\\nB - Observation Probability Matrix')\n",
    "    print(pd.DataFrame(example_model['B']))\n",
    "    print('The probability of being in hidden state 1 while observing observable state 2 is ' + str(example_model['B'][1][2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Problem 1. Determining the Best Model\n",
    "You are given a sequence of observations, $O$, and a few candidate HMMs, $\\{\\lambda_1=(A_1, B_1, \\pi_1), \\lambda_2=(A_2, B_2, \\pi_2)...\\}$. Your task is to find the model that best describes the sequence of observations. \n",
    "\n",
    "You could approach this problem by calculating $P(O\\mid\\lambda)$ for every $\\lambda$, and returning the index of the model yielding the highest likelihood.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\"><b>Hint:</b> The Forward Algorithm generates a table of size $T\\times N$ where $T$ is the length of the observation sequence. Then, $P(O\\mid\\lambda)$ is essentially the sum of the last row of this table. The Backward Algorithm works similarly. You may choose one to implement.</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\"><b>Note:</b> You must use dynamic programming in your implementation. Otherwise, the tests will timeout.</div>\n",
    "\n",
    "Implement your algorithm in the `find_model(O, models)` function below. Do NOT change the function signature. You are, however, free to define and use helper functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_algorithm(O, pi, A, B):\n",
    "    \"\"\"\n",
    "    Forward algorithm for Hidden Markov Models (HMM) using dynamic programming.\n",
    "\n",
    "    Args:\n",
    "        O = observations (list): List of observed symbols (emissions).\n",
    "        pi = initial_prob (dict): Initial state probabilities (pi).\n",
    "        A = transition_prob (np.ndarray): Transition probabilities matrix (A).\n",
    "        B =  Observation probability (aka emission prob) (dict) (B).\n",
    "\n",
    "    Returns:\n",
    "        float: The probability of observing the given sequence of emissions.\n",
    "    \"\"\"\n",
    "    T = len(O)  # Length of the observation sequence\n",
    "    N = len(pi)  # Number of hidden states\n",
    "\n",
    "    \n",
    "    alpha = np.zeros((T, N)) # Initialize the forward probabilities matrix\n",
    "\n",
    "    # Initialize the first column (t=0) with initial probabilities\n",
    "    for i, state in enumerate(range(N)):\n",
    "        alpha[0, i] = pi[state] * B[state][O[0]]\n",
    "\n",
    "    # compute forward probabilities for t = 1 to T-1\n",
    "    for t in range(1, T):\n",
    "        for j, state_j in enumerate(range(N)):\n",
    "            alpha[t, j] = sum(alpha[t - 1, i] * A[i, j] * B[state_j][O[t]] for i in range(N))\n",
    "\n",
    "    # finally, compute the total probability of the observation sequence\n",
    "    total_prob = sum(alpha[T - 1, i] for i in range(N))\n",
    "\n",
    "    return total_prob\n",
    "\n",
    "# # Example usage\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Define HMM parameters (toy example)\n",
    "#     observations = [\"A\", \"B\", \"A\"]  # Observed sequence\n",
    "#     states = [\"S1\", \"S2\"]  # Hidden states\n",
    "#     initial_prob = {\"S1\": 0.6, \"S2\": 0.4}  # Initial state probabilities\n",
    "#     transition_prob = np.array([[0.282549, 0.209212, 0.372559, 0.135680, 0.0],\n",
    "#                                 [0.465455, 0.153957, 0.068227, 0.312361, 0.0],\n",
    "#                                 [0.287679, 0.0, 0.589609, 0.029587, 0.093125],\n",
    "#                                 [0.223858, 0.310132, 0.114584, 0.351426, 0.0],\n",
    "#                                 [0.281112, 0.148761, 0.0, 0.436989, 0.133139]])  # Transition probabilities\n",
    "#     emission_prob = {\"S1\": {\"A\": 0.8, \"B\": 0.2}, \"S2\": {\"A\": 0.4, \"B\": 0.6}}  # Emission probabilities\n",
    "\n",
    "#     # Compute the probability of observing the given sequence\n",
    "#     #prob_observation = forward_algorithm(observations, states, initial_prob, transition_prob, emission_prob)\n",
    "#     #print(f\"Probability of observing {observations}: {prob_observation:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_model(O, models):\n",
    "    \"\"\"Finds the HMM that is mostly likely to have generated a given sequence of observations\n",
    "    Args:\n",
    "      O: A list of observed states.\n",
    "      models: a list of HMM models. E.x.models[0]['A'] accesses the transition matrix of the first HMM.\n",
    "    Returns: The index corresponding to the best-fit HMM.\n",
    "    \"\"\"\n",
    "    best_model_idx = -1\n",
    "    prob_of_best_model = -1\n",
    "    for idx, model in enumerate(models):\n",
    "\n",
    "        #get A, B, and pi from model\n",
    "        A, B, pi = model['A'], model['B'], model['pi']\n",
    "\n",
    "        #prob of the observation sequence\n",
    "        prob_of_seq = forward_algorithm(O=O, pi=pi, A=A, B=B)\n",
    "\n",
    "        if prob_of_seq > prob_of_best_model:\n",
    "            prob_of_best_model = prob_of_seq\n",
    "            best_model_idx = idx\n",
    "\n",
    "    assert best_model_idx != -1\n",
    "    return best_model_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run & Test\n",
    "Use the cell below to run and test `find_model(O, models)`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test 0....\n",
      "Running test 1....\n",
      "Running test 2....\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td><h4>Test</h4><td><td><h4>% of Correct Trials</h4><td><td><h4>Grade</h4><td></tr><tr><td><h4>0</h4><td><td><h4>68.0%</h4><td><td><h4>10 / 10</h4><td></tr><tr><td><h4>1</h4><td><td><h4>76.0%</h4><td><td><h4>10 / 10</h4><td></tr><tr><td><h4>2</h4><td><td><h4>62.0%</h4><td><td><h4>10 / 10</h4><td></tr><tr><td><h4><i>👻 Hidden test 0 👻</i></h4><td><td><h4><i>???</i></h4><td><td><h4><i>???</i> / 10</h4><td></tr><tr><td><h4><i>👻 Hidden test 1 👻</i></h4><td><td><h4><i>???</i></h4><td><td><h4><i>???</i> / 10</h4><td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    def test_metadata(N, M, T):\n",
    "        \"\"\"Gathers constants that describes a test\n",
    "        Args:\n",
    "          N: Number of hidden states.\n",
    "          M: Number of observable states.\n",
    "          T: Length of observable sequence.\n",
    "        \"\"\"\n",
    "        return {'N': N, 'M': M, 'T': T}\n",
    "    tests = [test_metadata(N=5, M=3, T=100), \n",
    "             test_metadata(N=10, M=5, T=200),\n",
    "             test_metadata(N=10, M=3, T=300)]    \n",
    "    output = [['Test', '% of Correct Trials', 'Grade']]\n",
    "    for idx, test in enumerate(tests):\n",
    "        print(\"Running test \" + str(idx) + \"....\")\n",
    "        count = 0\n",
    "        for trial in range(50):\n",
    "            # 1. Create Candidate HMMs\n",
    "            models = []\n",
    "            pi = np.ones((test['N']))\n",
    "            pi = pi / pi.sum()\n",
    "            for i in range(3):\n",
    "                models.append({'A': generate_matrix(test['N'], test['N'], i), \n",
    "                               'B': generate_matrix(test['N'], test['M'], i), \n",
    "                               'pi': pi})\n",
    "\n",
    "            # 2. Pick 1 HMM\n",
    "            TRUE_MODEL = random.randint(0,2) \n",
    "\n",
    "            # 3. Create observation based on model\n",
    "            OBS = []\n",
    "            for i in range(test['T']):\n",
    "                cur_h_state = 0\n",
    "                if(i == 0):\n",
    "                    cur_h_state = np.random.choice(np.arange(0, test['N']), p=models[TRUE_MODEL]['pi'])\n",
    "                else:\n",
    "                    cur_h_state = np.random.choice(np.arange(0, test['N']), p=models[TRUE_MODEL]['A'][int(cur_h_state)])\n",
    "                OBS.append(int(np.random.choice(np.arange(0, test['M']), p=models[TRUE_MODEL]['B'][int(cur_h_state)])))\n",
    "\n",
    "            # 3. Test find_model\n",
    "            est_model = find_model(OBS, models)\n",
    "            if(est_model == TRUE_MODEL):\n",
    "                count = count + 1\n",
    "        score = 10 if(count > (50 / len(tests))) else 0\n",
    "        output.append([idx, '{:.1%}'.format(count / 50), \"{:0.0f} / 10\".format(score)])  \n",
    "    output.append(['<i>👻 Hidden test 0 👻</i>','<i>???</i>', '<i>???</i> / 10'])\n",
    "    output.append(['<i>👻 Hidden test 1 👻</i>','<i>???</i>', '<i>???</i> / 10'])\n",
    "    display_table(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Problem 2. Recovering the Hidden States\n",
    "You are given a sequence of observed states and an HMM. Recover the most likely sequence of hidden states. You are encouraged to implement the Viterbi algorithm here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def recover_states(O, model):\n",
    "    \"\"\" Recovers the most likely sequence of hidden states given observations and a model\n",
    "    Args:\n",
    "      O: A list of observed states.\n",
    "      model: The HMM.\n",
    "    Returns: A list of hidden states\n",
    "    \"\"\"\n",
    "    \n",
    "    #get A, B, and pi from model\n",
    "    A, B, pi = model['A'], model['B'], model['pi']\n",
    "    T = len(O)  # Length of the observation sequence\n",
    "    N = len(pi)  # Number of hidden states\n",
    "\n",
    "\n",
    "    # Initialize the Viterbi matrix and backpointers\n",
    "    viterbi = np.zeros((T, N))\n",
    "    backpointers = np.zeros((T, N), dtype=int)\n",
    "\n",
    "    # Initialize the first column (t=0) with initial probabilities\n",
    "    for i, state in enumerate(range(N)):\n",
    "        viterbi[0, i] = pi[state] * B[state][O[0]]\n",
    "        backpointers[0, i] = -1  # No backpointer for the first column\n",
    "\n",
    "    #compute Viterbi probabilities and backpointers\n",
    "    for t in range(1, T):\n",
    "        for j, state_j in enumerate(range(N)):\n",
    "            max_prob = float(\"-inf\")\n",
    "            max_prev_state = None\n",
    "            for i, state_i in enumerate(range(N)):\n",
    "                prob = viterbi[t - 1, i] * A[state_i][state_j]\n",
    "                if prob > max_prob:\n",
    "                    max_prob = prob\n",
    "                    max_prev_state = i\n",
    "            viterbi[t, j] = max_prob * B[state_j][O[t]]\n",
    "            backpointers[t, j] = max_prev_state\n",
    "\n",
    "    # finally, find the most likely final state\n",
    "    final_state = np.argmax(viterbi[T - 1])\n",
    "\n",
    "    # Backtrack recovers state\n",
    "    x = [final_state]\n",
    "    for t in range(T - 1, 0, -1):\n",
    "        prev_state = backpointers[t, x[-1]]\n",
    "        x.append(prev_state)\n",
    "\n",
    "    # Reverse the list to get the correct order\n",
    "    x.reverse()\n",
    "\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run & Test\n",
    "Use the cell below to run and test `recover_states(O, model)`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test 0.....\n",
      "Running test 1.....\n",
      "Running test 2.....\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td><h4>Test</h4><td><td><h4>% of States Uncovered</h4><td><td><h4>Random Guessing</h4><td><td><h4>Grade</h4><td></tr><tr><td><h4>0</h4><td><td><h4>41.6%</h4><td><td><h4>18.8%</h4><td><td><h4>10 / 10</h4><td></tr><tr><td><h4>1</h4><td><td><h4>18.9%</h4><td><td><h4>10.6%</h4><td><td><h4>10 / 10</h4><td></tr><tr><td><h4>2</h4><td><td><h4>11.7%</h4><td><td><h4>8.5%</h4><td><td><h4>10 / 10</h4><td></tr><tr><td><h4><i>👻 Hidden test 0 👻</i></h4><td><td><h4><i>???</i></h4><td><td><h4><i>???</i></h4><td><td><h4><i>???</i> / 10</h4><td></tr><tr><td><h4><i>👻 Hidden test 1 👻</i></h4><td><td><h4><i>???</i></h4><td><td><h4><i>???</i></h4><td><td><h4><i>???</i> / 10</h4><td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    def test_metadata(N, M, T):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          N: Number of hidden states.\n",
    "          M: Number of observable states.\n",
    "          T: Length of observable sequence.\n",
    "        \"\"\"\n",
    "        return {'N': N, 'M': M, 'T': T}\n",
    "    def random_guessing(T, M):\n",
    "        return [random.randint(0,M-1) for i in range(T)]\n",
    "    tests = [test_metadata(N=5, M=3, T=100), \n",
    "             test_metadata(N=10, M=3, T=200),\n",
    "             test_metadata(N=12, M=3, T=300)]  \n",
    "    output = [['Test', '% of States Uncovered', 'Random Guessing', 'Grade']]\n",
    "    for idx, test in enumerate(tests):\n",
    "        score = 0\n",
    "        rand_score = 0\n",
    "        print(\"Running test \" + str(idx) + \".....\")\n",
    "        for trial in range(100):\n",
    "            # 1. Generate model\n",
    "            pi = np.ones((test['N']))\n",
    "            pi = pi / pi.sum()\n",
    "            model = {'A': generate_matrix(test['N'], test['N'], idx),\n",
    "                     'B': generate_matrix(test['N'], test['M'], idx),\n",
    "                     'pi': pi}\n",
    "            # 2. Generate observations and hidden states\n",
    "            OBS = []\n",
    "            TRUE_STATES = []\n",
    "            for i in range(test['T']):\n",
    "                cur_h_state = 0\n",
    "                if(i == 0):\n",
    "                    cur_h_state = np.random.choice(np.arange(0, test['N']), p=model['pi'])\n",
    "                else:\n",
    "                    cur_h_state = np.random.choice(np.arange(0, test['N']), p=model['A'][int(cur_h_state)])\n",
    "                OBS.append(int(np.random.choice(np.arange(0, test['M']), p=model['B'][int(cur_h_state)])))\n",
    "                TRUE_STATES.append(int(cur_h_state))\n",
    "            # 3. Test viterbi\n",
    "            est_states = recover_states(OBS, model)\n",
    "            random_states = random_guessing(test['T'], test['M'])\n",
    "            # 4. Calculate score\n",
    "            count = sum(x == y for x, y in zip(np.array(TRUE_STATES), np.array(est_states)))\n",
    "            score = score + count / test['T']\n",
    "            rand_count = sum(x == y for x, y in zip(np.array(TRUE_STATES), np.array(random_states)))\n",
    "            rand_score = rand_score + rand_count / test['T']\n",
    "        grade = 10 if(score > rand_score) else 0\n",
    "        output.append([idx, '{:.1%}'.format(score / 100), '{:.1%}'.format(rand_score / 100), \"{:0.0f} / 10\".format(grade)])\n",
    "    output.append(['<i>👻 Hidden test 0 👻</i>','<i>???</i>', '<i>???</i>', '<i>???</i> / 10'])\n",
    "    output.append(['<i>👻 Hidden test 1 👻</i>','<i>???</i>', '<i>???</i>', '<i>???</i> / 10'])\n",
    "    display_table(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Rubric\n",
    "Since HMM are probabilistic models, we will run your code many times and your grade should stabilize after many trials by the Law of Large Numbers. The script provided runs 50 trials to make testing more pleasant. The actual grading script will run more trials. **On Gradescope, we will display your total score, including hidden test cases. You can expect your final grade for this MP to match what you see after submission.**\n",
    "\n",
    "#### Determing the Best Model (50 points) \n",
    "You will be graded on the 3 sets of provided cases as well as 2 sets of hidden cases. 10 points will be rewarded if your algorithm performs better than random guessing. For example, if the test provides 5 models, your algorithm will receive full points if it outputs the correct model over 20% of the times.\n",
    "\n",
    "#### Recovering the Hidden States (50 points) \n",
    "You will be graded on the 3 sets of provided cases as well as 2 sets of hidden cases. 10 points will be rewarded if your algorithm recovered more states than random guessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Submission Guideline\n",
    "This Jupyter notebook is the only file you need to submit on Gradescope.\n",
    "\n",
    "**Make sure any code you added to this notebook, except for import statements, is either in a function or guarded by `__main__`(which won't be run by the autograder). Gradescope will give you immediate feedback using the provided test cases. It is your responsibility to check the output before the deadline to ensure your submission runs with the autograder.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
